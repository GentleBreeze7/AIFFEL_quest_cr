{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqzT18i/tBMb2D16kRJbha",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GentleBreeze7/AIFFEL_quest_cr/blob/main/LMSProject/6_2_%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8_(2)_load_wine_%EC%99%80%EC%9D%B8%EC%9D%84_%EB%B6%84%EB%A5%98%ED%95%B4_%EB%B4%85%EC%8B%9C%EB%8B%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oPNIkszBQImz"
      },
      "outputs": [],
      "source": [
        "# (1) 필요한 모듈 import하기\n",
        "# 데이터 로드, 데이터 분리, 평가 및 다양한 모델 생성을 위한 라이브러리를 가져옵니다.\n",
        "from sklearn.datasets import load_wine  # 와인 데이터를 로드\n",
        "from sklearn.model_selection import train_test_split  # 데이터를 학습/테스트 세트로 분리\n",
        "from sklearn.metrics import classification_report  # 모델 성능 평가\n",
        "from sklearn.tree import DecisionTreeClassifier  # 의사결정트리 모델\n",
        "from sklearn.ensemble import RandomForestClassifier  # 랜덤포레스트 모델\n",
        "from sklearn.svm import SVC  # 서포트 벡터 머신(SVM)\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression  # SGD와 로지스틱 회귀 모델"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (2) 데이터 준비\n",
        "# load_wine 메서드를 통해 데이터를 로드합니다.\n",
        "wine = load_wine()  # 와인 데이터 로드"
      ],
      "metadata": {
        "id": "UrNJNTPXQxDX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (3) 데이터 이해하기\n",
        "# Feature Data 지정하기\n",
        "X = wine.data  # 와인 데이터를 설명하는 Feature 값들 (13개의 특성)\n",
        "\n",
        "# Label Data 지정하기\n",
        "y = wine.target  # 와인의 종류를 나타내는 Label 값 (0, 1, 2로 구분)\n",
        "\n",
        "# Target Names 출력해 보기\n",
        "print(\"Target Names:\", wine.target_names)  # 와인의 종류 이름 (class_0, class_1, class_2)\n",
        "\n",
        "# 데이터 Describe 해 보기\n",
        "# 데이터의 기본 정보를 출력해 특성과 구조를 파악합니다.\n",
        "print(\"\\nFeature Names:\", wine.feature_names)  # Feature 이름 출력\n",
        "print(\"\\nShape of Data:\", X.shape)  # Feature 데이터의 크기 출력 (행 개수와 열 개수)\n",
        "print(\"\\nFirst 5 rows of Data:\\n\", X[:5])  # 데이터 샘플 출력 (처음 5개 행)\n",
        "print(\"\\nLabel Distribution:\", {i: list(y).count(i) for i in set(y)})  # 각 클래스의 데이터 수 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqSloE3sQyOR",
        "outputId": "b39d35e8-47c4-442b-ed5c-259f78d876f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Names: ['class_0' 'class_1' 'class_2']\n",
            "\n",
            "Feature Names: ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
            "\n",
            "Shape of Data: (178, 13)\n",
            "\n",
            "First 5 rows of Data:\n",
            " [[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
            "  2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
            " [1.320e+01 1.780e+00 2.140e+00 1.120e+01 1.000e+02 2.650e+00 2.760e+00\n",
            "  2.600e-01 1.280e+00 4.380e+00 1.050e+00 3.400e+00 1.050e+03]\n",
            " [1.316e+01 2.360e+00 2.670e+00 1.860e+01 1.010e+02 2.800e+00 3.240e+00\n",
            "  3.000e-01 2.810e+00 5.680e+00 1.030e+00 3.170e+00 1.185e+03]\n",
            " [1.437e+01 1.950e+00 2.500e+00 1.680e+01 1.130e+02 3.850e+00 3.490e+00\n",
            "  2.400e-01 2.180e+00 7.800e+00 8.600e-01 3.450e+00 1.480e+03]\n",
            " [1.324e+01 2.590e+00 2.870e+00 2.100e+01 1.180e+02 2.800e+00 2.690e+00\n",
            "  3.900e-01 1.820e+00 4.320e+00 1.040e+00 2.930e+00 7.350e+02]]\n",
            "\n",
            "Label Distribution: {0: 59, 1: 71, 2: 48}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (4) train, test 데이터 분리\n",
        "# 데이터를 학습용과 테스트용으로 나눕니다.\n",
        "# stratify=y는 데이터 클래스 비율을 학습/테스트 세트에 동일하게 유지합니다.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "EdtTxqXXQ0u0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5) 다양한 모델로 학습시켜보기\n",
        "# Decision Tree\n",
        "# 의사결정트리 분류기를 학습시킵니다.\n",
        "dt_model = DecisionTreeClassifier(random_state=42)  # 모델 생성\n",
        "dt_model.fit(X_train, y_train)  # 학습 데이터로 모델 학습\n",
        "dt_preds = dt_model.predict(X_test)  # 테스트 데이터로 예측\n",
        "\n",
        "# Random Forest\n",
        "# 랜덤포레스트 분류기를 학습시킵니다.\n",
        "rf_model = RandomForestClassifier(random_state=42)  # 모델 생성\n",
        "rf_model.fit(X_train, y_train)  # 학습 데이터로 모델 학습\n",
        "rf_preds = rf_model.predict(X_test)  # 테스트 데이터로 예측\n",
        "\n",
        "# SVM\n",
        "# 서포트 벡터 머신(SVM)을 학습시킵니다.\n",
        "svm_model = SVC(random_state=42)  # 모델 생성\n",
        "svm_model.fit(X_train, y_train)  # 학습 데이터로 모델 학습\n",
        "svm_preds = svm_model.predict(X_test)  # 테스트 데이터로 예측\n",
        "\n",
        "# SGD Classifier\n",
        "# 확률적 경사 하강법(SGD) 분류기를 학습시킵니다.\n",
        "sgd_model = SGDClassifier(random_state=42)  # 모델 생성\n",
        "sgd_model.fit(X_train, y_train)  # 학습 데이터로 모델 학습\n",
        "sgd_preds = sgd_model.predict(X_test)  # 테스트 데이터로 예측\n",
        "\n",
        "# Logistic Regression\n",
        "# 로지스틱 회귀 모델을 학습시킵니다.\n",
        "lr_model = LogisticRegression(max_iter=2000, random_state=42)  # 모델 생성 (최대 반복 횟수 2000)\n",
        "lr_model.fit(X_train, y_train)  # 학습 데이터로 모델 학습\n",
        "lr_preds = lr_model.predict(X_test)  # 테스트 데이터로 예측"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKuClc48RCw7",
        "outputId": "8fc68ddd-bbdc-4f47-9f2a-c2b68466134c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해 보기\n",
        "# classification_report를 사용하여 모델의 성능을 평가합니다.\n",
        "# 주요 지표: Precision(정밀도), Recall(재현율), F1-score(정밀도와 재현율의 조화 평균)\n",
        "print(\"\\nDecision Tree Classification Report:\\n\", classification_report(y_test, dt_preds, target_names=wine.target_names))\n",
        "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test, rf_preds, target_names=wine.target_names))\n",
        "print(\"\\nSVM Classification Report:\\n\", classification_report(y_test, svm_preds, target_names=wine.target_names))\n",
        "print(\"\\nSGD Classifier Classification Report:\\n\", classification_report(y_test, sgd_preds, target_names=wine.target_names))\n",
        "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, lr_preds, target_names=wine.target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBL0Tp9gRfWU",
        "outputId": "abbada39-0e58-4c80-84fa-897fe816cb0e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     class_0       1.00      0.92      0.96        12\n",
            "     class_1       0.88      1.00      0.93        14\n",
            "     class_2       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.94        36\n",
            "   macro avg       0.96      0.94      0.95        36\n",
            "weighted avg       0.95      0.94      0.94        36\n",
            "\n",
            "\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     class_0       1.00      1.00      1.00        12\n",
            "     class_1       1.00      1.00      1.00        14\n",
            "     class_2       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n",
            "\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     class_0       0.92      0.92      0.92        12\n",
            "     class_1       0.61      1.00      0.76        14\n",
            "     class_2       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.69        36\n",
            "   macro avg       0.51      0.64      0.56        36\n",
            "weighted avg       0.54      0.69      0.60        36\n",
            "\n",
            "\n",
            "SGD Classifier Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     class_0       1.00      0.92      0.96        12\n",
            "     class_1       1.00      0.43      0.60        14\n",
            "     class_2       0.53      1.00      0.69        10\n",
            "\n",
            "    accuracy                           0.75        36\n",
            "   macro avg       0.84      0.78      0.75        36\n",
            "weighted avg       0.87      0.75      0.74        36\n",
            "\n",
            "\n",
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     class_0       1.00      1.00      1.00        12\n",
            "     class_1       0.88      1.00      0.93        14\n",
            "     class_2       1.00      0.80      0.89        10\n",
            "\n",
            "    accuracy                           0.94        36\n",
            "   macro avg       0.96      0.93      0.94        36\n",
            "weighted avg       0.95      0.94      0.94        36\n",
            "\n"
          ]
        }
      ]
    }
  ]
}